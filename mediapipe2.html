<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>MediaPipe Handtracking Example</title>
    <style>
        body {
            margin: 0;
            background: #15172a;
            transition: background-color .3s ease-out;
            color: #fff;
            display: flex;
            flex-direction: column;
            align-items: center;
            font-family: sans-serif;
            min-height: 100vh;
            justify-content: center;
        }

        #container {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1em;
            position: relative; /* for absolute overlay alignment */
        }

        video,
        canvas {
            border-radius: 10px;
            box-shadow: 0 2px 16px #0007;
            max-width: 100vw;
            background: #000;
        }
        video.mirrored {
            transform: scaleX(-1);
        }

        canvas.landscape {
            width: 640px;
            height: 480px;
        }
        #three_overlay {
            width: 480px;
            height: 640px;
            background-color: transparent;
        }
        #three_overlay.landscape {
            width: 640px;
            height: 480px;
        }

        video {
            display: none;
        }

        h1 {
            margin-bottom: 1em;
            font-weight: 600;
            letter-spacing: 0.04em;
            color: #91b5f4;
        }
    </style>
    <!-- MediaPipe Hands CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.min.js"></script>
    <!-- Three.js -->
    <script src="https://unpkg.com/three@0.160.0/build/three.min.js"></script>
</head>

<body>
    <div id="container">
        <h1>MediaPipe Handtracking Example</h1>
        <video id="input_video" class="mirrored" muted autoplay playsinline></video>
        <canvas id="output_canvas"></canvas>
    </div>
    <script>
        const videoElement = document.getElementById('input_video');
        const canvasElement = document.getElementById('output_canvas');
        const canvasCtx = canvasElement.getContext('2d');

        // MediaPipe Hands setup
        const hands = new Hands({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
        });
        hands.setOptions({
            maxNumHands: 2,
            modelComplexity: 1,
            minDetectionConfidence: 0.6,
            minTrackingConfidence: 0.7
        });

        hands.onResults(onResults);

        function onResults(results) {
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            // Draw the video frame
            canvasCtx.drawImage(
                results.image, 0, 0, canvasElement.width, canvasElement.height);

            if (results.multiHandLandmarks) {
                for (const landmarks of results.multiHandLandmarks) {
                    drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS,
                        { color: '#00C3FF', lineWidth: 2.5 });
                    drawLandmarks(canvasCtx, landmarks, { color: '#FFD700', lineWidth: 1 });
                }
            }
            canvasCtx.restore();
        }

        // Camera/Webcam streaming setup
        window.camera = null;
    </script>

    <div style="margin:1em 0;">
        <label for="facing_mode_select"><strong>Camera:</strong></label>
        <select id="facing_mode_select" style="font-size:1em;">
            <option value="user">Front Facing</option>
            <option value="environment">Rear Facing</option>
        </select>

        <label for="device_select" style="margin-left:2em;"><strong>Exact Device:</strong></label>
        <select id="device_select" style="font-size:1em;">
            <option value="">(Choose device...)</option>
            <!-- Devices will be populated dynamically -->
        </select>
    </div>
    <script>
        // Reference to camera instance
        //   let currentFacingMode = 'user';

        // Helper to start MediaPipe camera with specified facingMode
        async function startMediaPipeCamera(facingMode) {
            // Patch: forcibly restart MediaPipe's camera frame loop
            if (camera && typeof camera.stop === 'function') camera.stop();

            // Stop previous stream if any
            if (videoElement.srcObject) {
                videoElement.srcObject.getTracks().forEach(track => track.stop());
            }
            // alert(facingMode);
            // Find constraints for camera (prefer facing mode)
            const constraints = {
                audio: false,
                video: {
                    width: { ideal: 4096 },
                    height: { ideal: 2160 },
                    // facingMode: { ideal: facingMode }
                    facingMode: facingMode
                }
            };
            // Get media stream
            try {
                const stream = await navigator.mediaDevices.getUserMedia(constraints);

                if (navigator.mediaDevices && navigator.mediaDevices.enumerateDevices) {
                    navigator.mediaDevices.enumerateDevices().then(devices => {
                        const videoInputs = devices.filter(device => device.kind === 'videoinput');
                        console.log('Available cameras:', videoInputs);

                        // populate #device_select with list of device names,
                        // the value is the device id
                        // Populate the #device_select dropdown
                        const deviceSelect = document.getElementById('device_select');
                        // Clear existing options except the placeholder
                        deviceSelect.innerHTML = '<option value="">(Choose device...)</option>';
                        videoInputs.forEach(device => {
                            const option = document.createElement('option');
                            option.value = device.deviceId;
                            option.textContent = device.label || `Camera ${deviceSelect.length}`;
                            deviceSelect.appendChild(option);
                        });

                    }).catch(e => {
                        console.warn('Error enumerating media devices:', e);
                    });
                } else {
                    console.warn('enumerateDevices() not supported on this browser.');
                }

                videoElement.srcObject = stream;
                await videoElement.play();
                
                setTimeout(()=>{
                    // Restart MediaPipe camera with updated facing mode
                    const newCamera = new Camera(videoElement, {
                        onFrame: async () => {
                            await hands.send({ image: videoElement });
                        },
                        width: 640,
                        height: 480
                    });
                    newCamera.start();
                    //   alert('new cam:'+facingMode)
                    window.camera = newCamera; // update the reference globally, if desired
                },1000)
                currentFacingMode = facingMode;


            } catch (err) {
                console.error(err)
                console.error('Could not access camera: ' + err.message);
            }
        }

        async function startMediaPipeCamera_EXACT_DEVICE_ID(selectedDeviceId) {
            try {
                // Stop any existing camera stream if needed
                if (window.camera && window.camera.video) {
                    let tracks = window.camera.video.srcObject && window.camera.video.srcObject.getTracks();
                    if (tracks) tracks.forEach(track => track.stop());
                }
                // Get video element
                const videoElement = document.getElementById('input_video');
                // GetMedia with deviceId exact
                const constraints = {
                    video: {
                        deviceId: { exact: selectedDeviceId },
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }
                };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                videoElement.srcObject = stream;
                await videoElement.play();

                // Restart MediaPipe camera with selected device stream
                const newCamera = new Camera(videoElement, {
                    onFrame: async () => {
                        await hands.send({ image: videoElement });
                    },
                    width: 640,
                    height: 480
                });
                newCamera.start();
                window.camera = newCamera;
                // Optionally, update global facing mode reference
                // currentFacingMode = null;
            } catch (err) {
                console.error(err);
                alert('Could not access selected camera: ' + err.message);
            }
        }

        // Setup facing mode switcher UI
        document.getElementById('facing_mode_select').addEventListener('change', function (e) {
            const facingMode = e.target.value;
            startMediaPipeCamera(facingMode);
        });

        // setup device select change handler -> startMediaPipeCamera_EXACT_DEVICE_ID
        // Listen for device selection changes and restart the camera with the chosen device
        document.getElementById('device_select').addEventListener('change', function (e) {
            const deviceId = e.target.value;
            // If a device is selected, start camera with exact device ID
            if (deviceId) {
                // Provide a custom startMediaPipeCamera invocation that uses constraints with deviceId
                // Define a variant to handle exact deviceId (if not already defined)
                startMediaPipeCamera_EXACT_DEVICE_ID(deviceId);
            }
        });

        // On load, use default facing mode IF on mobile (switch to rear camera)
        document.addEventListener('DOMContentLoaded', () => {
            // Try environment facing if on mobile
            // const isMobile = /Android|iPhone|iPad|iPod/i.test(navigator.userAgent);
            // if (isMobile) {
            //   document.getElementById('facing_mode_select').value = 'environment';
            startMediaPipeCamera('environment');
            // }
        });
    </script>
</body>

</html>
<script>
    // Utility to detect pinch (thumb tip and index tip close together)
    function isPinching(landmarks) {
        // Thumb tip: 4
        // Index tip: 8
        const dx = landmarks[4].x - landmarks[8].x;
        const dy = landmarks[4].y - landmarks[8].y;
        const dz = (landmarks[4].z || 0) - (landmarks[8].z || 0);
        const dist = Math.sqrt(dx * dx + dy * dy + dz * dz);
        return dist < 0.085; // Tweak threshold as needed
    }

    // Track pinch state to avoid flicker
    let pinchBgState = null;

    // Decorate the MediaPipe onResults handler to add the BG color logic
    const origOnResults = onResults;
    function bgPinchOnResults(results) {
        origOnResults(results);

        let leftPinch = false, rightPinch = false;
        let pinchCenter = null; // normalized [0..1] coords in video space

        if (results.multiHandLandmarks && results.multiHandedness) {
            for (let i = 0; i < results.multiHandLandmarks.length; ++i) {
                const landmarks = results.multiHandLandmarks[i];
                const handedness = results.multiHandedness[i].label; // "Left" or "Right"
                if (isPinching(landmarks)) {
                    if (handedness === 'Left') leftPinch = true;
                    if (handedness === 'Right') rightPinch = true;
                    // Use the first detected pinching hand center
                    if (!pinchCenter) {
                        pinchCenter = {
                            x: (landmarks[4].x + landmarks[8].x) * 0.5,
                            y: (landmarks[4].y + landmarks[8].y) * 0.5
                        };
                    }
                }
            }
        }

        // Decide on BG color/state
        let newState = null;
        if (leftPinch) newState = 'green';
        else if (rightPinch) newState = 'purple';

        if (newState !== pinchBgState) {
            pinchBgState = newState;
            if (newState === 'green') {
                document.body.style.background = '#357e40';
            } else if (newState === 'purple') {
                document.body.style.background = '#8d45ae';
            } else {
                document.body.style.background = '';
            }
        }

        // Three.js pinch interactions
        handlePinchForThree(pinchCenter);
    }
    // Swap handler
    hands.onResults(bgPinchOnResults);
</script>
<script>
    // Three.js overlay, cube, and pinch-based interaction with inertia
    let threeScene = null;
    let threeCamera = null;
    let threeRenderer = null;
    let threeRaycaster = null;
    let threeCube = null;
    let threeHitMarker = null;
    let angularVelocityZ = 0;
    let lastFrameTs = 0;
    let dragActive = false;
    let wasPinching = false;
    let lastPinch = null; // { x: normalized 0..1, y: normalized 0..1 }

    function initThreeOverlay() {
        const container = document.getElementById('container');
        const targetCanvas = document.getElementById('output_canvas');
        if (!container || !targetCanvas || !window.THREE) return;

        threeScene = new THREE.Scene();
        threeCamera = new THREE.PerspectiveCamera(45, 1, 0.01, 100);
        threeCamera.position.set(0, 0, 3);

        threeRenderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        threeRenderer.setPixelRatio(window.devicePixelRatio || 1);
        // Enable soft shadows
        threeRenderer.shadowMap.enabled = true;
        threeRenderer.shadowMap.type = THREE.PCFSoftShadowMap;
        threeRenderer.domElement.id = 'three_overlay';
        threeRenderer.domElement.style.position = 'absolute';
        threeRenderer.domElement.style.top = '0';
        threeRenderer.domElement.style.left = '0';
        threeRenderer.domElement.style.pointerEvents = 'none';
        container.appendChild(threeRenderer.domElement);

        // Simple cube
        const geometry = new THREE.BoxGeometry(1, 1, 1);
        const material = new THREE.MeshStandardMaterial({ color: 0x66ccff, roughness: 0.4, metalness: 0.1, transparent: true, opacity: 0.8 });
        threeCube = new THREE.Mesh(geometry, material);
        threeCube.castShadow = true;
        threeCube.receiveShadow = true;
        threeScene.add(threeCube);

        // Lights
        const ambient = new THREE.AmbientLight(0xffffff, 0.6);
        const dir = new THREE.DirectionalLight(0xffffff, 0.8);
        dir.position.set(2, 3, 4);
        threeScene.add(ambient, dir);

        // Point light near camera, slightly to the right, casting shadows
        const point = new THREE.PointLight(0xffffff, 0.8, 0, 2);
        point.castShadow = true;
        point.shadow.mapSize.width = 1024;
        point.shadow.mapSize.height = 1024;
        point.position.set(0.6, 0.2, -0.5); // relative to camera
        threeCamera.add(point);
        threeScene.add(threeCamera);

        threeRaycaster = new THREE.Raycaster();

        // Red sphere hit marker (initially hidden)
        const markerGeom = new THREE.SphereGeometry(0.05, 24, 16);
        const markerMat = new THREE.MeshStandardMaterial({ color: 0xff3333, emissive: 0x660000, roughness: 0.5, metalness: 0.0 });
        threeHitMarker = new THREE.Mesh(markerGeom, markerMat);
        threeHitMarker.visible = false;
        threeScene.add(threeHitMarker);

        layoutThreeOverlay();
        window.addEventListener('resize', layoutThreeOverlay);
        // In case fonts/layout change heights
        window.addEventListener('orientationchange', layoutThreeOverlay);

        lastFrameTs = performance.now();
        requestAnimationFrame(threeAnimate);

        const isMobile = /Android|iPhone|iPad|iPod/i.test(navigator.userAgent);
            if(!isMobile){
                document.getElementById('three_overlay').classList.add('landscape');
                document.getElementById('output_canvas').classList.add('landscape');
            }
    }

    function layoutThreeOverlay() {
        if (!threeRenderer || !threeCamera) return;
        const container = document.getElementById('container');
        const targetCanvas = document.getElementById('output_canvas');
        const w = targetCanvas.clientWidth;
        const h = targetCanvas.clientHeight;
        // Position overlay directly over the target canvas inside container
        const left = targetCanvas.offsetLeft;
        const top = targetCanvas.offsetTop;
        threeRenderer.domElement.style.left = left + 'px';
        threeRenderer.domElement.style.top = top + 'px';
        threeRenderer.setSize(w, h, false);
        threeCamera.aspect = w / Math.max(1, h);
        threeCamera.updateProjectionMatrix();
    }

    function screenToNdcFromPinch(normalizedPinch) {
        // MediaPipe gives normalized [0..1] in image space
        // Convert to NDC: x_ndc in [-1,1], y_ndc in [-1,1] (y inverted)
        const x = normalizedPinch.x * 2 - 1;
        const y = -(normalizedPinch.y * 2 - 1);
        return { x, y };
    }

    function handlePinchForThree(pinchCenterOrNull) {
        const nowPinching = !!pinchCenterOrNull;
        const nowTs = performance.now();

        if (nowPinching && !wasPinching) {
            // Pinch start
            lastPinch = pinchCenterOrNull;
            // Raycast to decide if we grab the cube
            if (threeCamera && threeRaycaster && threeCube) {
                const ndc = screenToNdcFromPinch(pinchCenterOrNull);
                const vec2 = new THREE.Vector2(ndc.x, ndc.y);
                threeRaycaster.setFromCamera(vec2, threeCamera);
                const hits = threeRaycaster.intersectObjects([threeCube], true);
                dragActive = hits.length > 0;
                // Place/update hit marker at hit point, attach to cube so it follows rotations
                if (hits.length > 0) {
                    const hit = hits[0];
                    const worldPoint = hit.point.clone();
                    // Convert to cube local so it tracks rotation/transform
                    const localPoint = threeCube.worldToLocal(worldPoint);
                    if (threeHitMarker) {
                        // Ensure marker is a child of the cube to stick to surface during rotation
                        threeCube.add(threeHitMarker);
                        threeHitMarker.position.copy(localPoint);
                        threeHitMarker.visible = true;
                    }
                } else if (threeHitMarker) {
                    threeHitMarker.visible = false;
                }
            } else {
                dragActive = false;
            }
        } else if (nowPinching && wasPinching) {
            // Pinch move
            if (dragActive && threeCube && lastPinch) {
                const dxNorm = (pinchCenterOrNull.x - lastPinch.x);
                // Map horizontal normalized movement to Z rotation
                const angularDelta = dxNorm * Math.PI; // 180 deg per full width drag
                const dt = Math.max(1e-3, (nowTs - (lastFrameTs || nowTs)) / 1000);
                threeCube.rotation.y += angularDelta;
                angularVelocityZ = angularDelta / dt;
            }
            lastPinch = pinchCenterOrNull;
        } else if (!nowPinching && wasPinching) {
            // Pinch end -> release with inertia
            dragActive = false;
            lastPinch = null;
        }
        wasPinching = nowPinching;
    }

    function threeAnimate(ts) {
        const dt = Math.max(1e-3, (ts - lastFrameTs) / 1000);
        lastFrameTs = ts;

        // Inertial spin after release
        if (!dragActive && threeCube && Math.abs(angularVelocityZ) > 1e-4) {
            threeCube.rotation.y += angularVelocityZ * dt;
            // Exponential damping
            const damping = Math.exp(-3.2 * dt); // tweak friction
            angularVelocityZ *= damping;
            if (Math.abs(angularVelocityZ) < 1e-4) angularVelocityZ = 0;
        }

        if (threeRenderer && threeScene && threeCamera) {
            threeRenderer.render(threeScene, threeCamera);
        }
        requestAnimationFrame(threeAnimate);
    }

    // Initialize once DOM is ready (elements exist)
    if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', initThreeOverlay, { once: true });
    } else {
        initThreeOverlay();
    }
</script>